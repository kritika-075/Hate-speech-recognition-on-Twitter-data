# -*- coding: utf-8 -*-
"""2019201075_htspc.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1eJKRTJSioFF5fRKxjnGD1mhA8FOO_Vxq
"""
import warnings
warnings.filterwarnings("ignore")
import numpy as np
import pandas as pd
from sklearn.feature_extraction.text import TfidfVectorizer
import string
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score
from sklearn.metrics import confusion_matrix
from nltk.stem import PorterStemmer
from nltk.stem import LancasterStemmer
import nltk
# nltk.download('punkt')
# nltk.download('wordnet')
# nltk.download('stopwords')
# nltk.download('averaged_perceptron_tagger')
from nltk.tokenize import word_tokenize
from nltk.corpus import wordnet as wn
from nltk.corpus import stopwords
from nltk import pos_tag
from collections import defaultdict
from nltk.stem import WordNetLemmatizer
from sklearn.preprocessing import LabelEncoder
from nltk.tokenize import sent_tokenize
import sys

dir_train=sys.argv[1]
dir_test=sys.argv[2]
df=pd.read_csv(dir_train,encoding='latin-1')
df1=pd.read_csv(dir_test,encoding='latin-1')
df['text'] = df['text'].str.lower()
df1['text'] = df1['text'].str.lower()
dataset=pd.concat([df['text'],df1['text']], axis=0, join='outer')
dataset=pd.DataFrame(dataset)
dataset.insert(1,"text_new","any")
col=[]
for entry in dataset["text"]:
  port = WordNetLemmatizer()
  stem_sentence=[]
  entry=entry.replace('[{}]'.format(string.punctuation), '')
  entry=entry.replace("\n",' ')
  entry=entry.replace("[!#?,.::\"]",'')
  entry=entry.encode('ascii', 'ignore').decode('ascii')
  token_words=word_tokenize(entry)
  for word in token_words:
      stem_sentence.append(port.lemmatize(word))
      stem_sentence.append(" ")
  col.append(str(stem_sentence))
dataset["text_new"]=np.array(col)

y_df=df['labels']
Tf_vec = TfidfVectorizer(min_df=1,stop_words='english')
total=Tf_vec.fit_transform(dataset["text_new"])
total=total.toarray()
y_train=y_df
b=len(y_train)
x_train=total[:b]
x_test=total[b:]
clf = SVC(kernel='rbf')
clf.fit(x_train,y_train)
predict=clf.predict(x_test)
l=np.arange(1153)
l1=[l,predict]
l=np.asarray(l1)
np.savetxt("submission.csv",l.T,delimiter=',', fmt=['%d','%d'],header=',labels', comments='')